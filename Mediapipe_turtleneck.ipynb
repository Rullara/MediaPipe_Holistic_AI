{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf19206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/sbr/아무거나/jupyternotebook_for_AI/.ipynb_checkpoints\n",
      "c:/sbr/아무거나/jupyternotebook_for_AI/face_kazuhito.ipynb\n",
      "c:/sbr/아무거나/jupyternotebook_for_AI/Holistic\n",
      "c:/sbr/아무거나/jupyternotebook_for_AI/Mediapipe_turtleneck.ipynb\n",
      "c:/sbr/아무거나/jupyternotebook_for_AI/modules\n",
      "c:/sbr/아무거나/jupyternotebook_for_AI/utils\n",
      "c:/sbr/아무거나/jupyternotebook_for_AI/video.mp4\n",
      "c:/sbr/아무거나/jupyternotebook_for_AI/__pycache__\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_bool(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: bool) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: 0.5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_652/3903561578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Holistic 객체(어떠한 행위를 하는 친구) 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHolisticDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\sbr\\아무거나\\jupyternotebook_for_AI\\HolisticModule.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, static_image_mode, model_complexity, smooth_landmarks, min_detection_confidence, min_tracking_confidence)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\first_ai\\lib\\site-packages\\mediapipe\\python\\solutions\\holistic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, static_image_mode, model_complexity, smooth_landmarks, enable_segmentation, smooth_segmentation, refine_face_landmarks, min_detection_confidence, min_tracking_confidence)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \"\"\"\n\u001b[0;32m    113\u001b[0m     \u001b[0m_download_oss_pose_landmark_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_complexity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     super().__init__(\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mbinary_graph_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_BINARYPB_FILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         side_inputs={\n",
      "\u001b[1;32m~\\anaconda3\\envs\\first_ai\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, side_inputs, outputs)\u001b[0m\n\u001b[0;32m    256\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve_output_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     self._input_side_packets = {\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_side_input_type_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mside_inputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\first_ai\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     self._input_side_packets = {\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_side_input_type_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mside_inputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     }\n",
      "\u001b[1;32m~\\anaconda3\\envs\\first_ai\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36m_make_packet\u001b[1;34m(self, packet_data_type, data)\u001b[0m\n\u001b[0;32m    511\u001b[0m           data, image_format=image_frame.ImageFormat.SRGB)\n\u001b[0;32m    512\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacket_creator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpacket_data_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m   def _get_packet_content(self, packet_data_type: _PacketDataType,\n",
      "\u001b[1;31mTypeError\u001b[0m: create_bool(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: bool) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: 0.5"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from win10toast import ToastNotifier\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"c:/sbr/아무거나/jupyternotebook_for_AI/modules\"))\n",
    "import HolisticModule as hm\n",
    "from turtle_neck import turtlenect_detection\n",
    "from sleep_detect_angle import sleepiness_detection\n",
    "from fps import fps_present\n",
    "\n",
    "\n",
    "# video input \n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "folderPath = \"c:/sbr/아무거나/jupyternotebook_for_AI\"\n",
    "myList = os.listdir(folderPath)\n",
    "overlayList = []\n",
    "\n",
    "o_count = 0\n",
    "x_count = 0\n",
    "like_count = 0 \n",
    "o_present_count = 0\n",
    "x_present_count = 0\n",
    "like_present_count = 0\n",
    "\n",
    "epsilon = 1.0e-10\n",
    "\n",
    "for imPath in myList:\n",
    "    image = cv2.imread(f'{folderPath}/{imPath}')\n",
    "    print(f'{folderPath}/{imPath}')\n",
    "    overlayList.append(image)\n",
    "\n",
    "# Holistic 객체(어떠한 행위를 하는 친구) 생성\n",
    "detector = hm.HolisticDetector()\n",
    "\n",
    "while True:\n",
    "    # defalut BGR img\n",
    "    success, img = cap.read()\n",
    "    # mediapipe를 거친 이미지 생성 -> img\n",
    "    img = detector.findHolistic(img, draw=True)\n",
    "    # output -> list ( id, x, y, z) 32 개 좌표인데 예를 들면, (11, x, y, z)\n",
    "    pose_lmList = detector.findPoseLandmark(img, draw=False)\n",
    "    # 468개의 얼굴 점 리스트\n",
    "    face_lmList = detector.findFaceLandmark(img, draw=False)\n",
    "    \n",
    "    left_hand_lmList = detector.findLefthandLandmark(img, draw=False)\n",
    "    right_hand_lmList = detector.findRighthandLandmark(img, draw=False)\n",
    "\n",
    "    if len(face_lmList) != 0:\n",
    "        sleepiness_detection(detector, img, log=False, notification=False)\n",
    "\n",
    "    if len(pose_lmList) != 0 and len(face_lmList) != 0:\n",
    "        turtlenect_detection(detector, img, sensitivity = 9, log=False, notification=False)\n",
    "\n",
    "    # 인체가 감지가 되었는지 확인하는 구문\n",
    "    if len(left_hand_lmList) != 0 and len(right_hand_lmList) != 0:\n",
    "\n",
    "        # To detect O gesture\n",
    "        thumb_length = detector.findLength_lh_rh(4, 4)\n",
    "        index_length = detector.findLength_lh_rh(8, 8)\n",
    "        left_hand_length = detector.findLength_lh_lh(8,4)\n",
    "        left_threshold_length = detector.findLength_lh_lh(0,17)\n",
    "        right_hand_length = detector.findLength_rh_rh(8,4)\n",
    "        right_threshold_length = detector.findLength_rh_rh(0,17)\n",
    "\n",
    "        # To detect X gesture\n",
    "        left_hand_fingersUp_list_a0 = detector.left_hand_fingersUp(axis=False)\n",
    "        right_hand_fingersUp_list_a0 = detector.right_hand_fingersUp(axis=False)\n",
    "        index_mcp_length = detector.findLength_lh_rh(5, 5)\n",
    "        left_index_length = detector.findLength_lh_rh(7, 7)\n",
    "        # print(left_hand_fingersUp_list_a0, right_hand_fingersUp_list_a0)\n",
    "    \n",
    "        # To detect LIKE gesture\n",
    "        left_hand_fingersUp_list_a1 = detector.left_hand_fingersUp(axis=True)\n",
    "        right_hand_fingersUp_list_a1 = detector.right_hand_fingersUp(axis=True)    \n",
    "        # print(left_hand_fingersUp_list_a1, right_hand_fingersUp_list_a1)\n",
    "\n",
    "        if len(pose_lmList) != 0:\n",
    "            wrist_length = detector.findLength_pose(16,15)\n",
    "            shoulder_length = detector.findLength_pose(12,11)\n",
    "            elbow_length = detector.findLength_pose(13,14)\n",
    "            cross_length_1 = detector.findLength_pose(15,14)\n",
    "            cross_length_2 = detector.findLength_pose(16,13)\n",
    "        \n",
    "\n",
    "        # O detect\n",
    "        if left_hand_fingersUp_list_a0[2:] == [1,1,1] and left_hand_fingersUp_list_a0[2:] == [1,1,1] and thumb_length < 50 and index_length < 50 and left_hand_length > left_threshold_length and right_hand_length > right_threshold_length:\n",
    "            o_count += 1\n",
    "            x_present_count = 0\n",
    "            like_present_count = 0\n",
    "\n",
    "        # O detect\n",
    "        elif pose_lmList[16][1] < pose_lmList[15][1] and wrist_length < shoulder_length and pose_lmList[16][2] < pose_lmList[10][2] and pose_lmList[15][2] < pose_lmList[9][2] and elbow_length > shoulder_length:\n",
    "            o_count += 1\n",
    "            x_present_count = 0\n",
    "            like_present_count = 0\n",
    "                    \n",
    "        # X detect\n",
    "        elif left_hand_fingersUp_list_a0[2:] == [0,0,0] and left_hand_fingersUp_list_a0[2:] == [0,0,0] and right_hand_lmList[8][1]+ 15 > left_hand_lmList[8][1]  and left_index_length < left_threshold_length and index_mcp_length < 150:\n",
    "            x_count += 1\n",
    "            o_present_count = 0\n",
    "            like_present_count = 0\n",
    "        \n",
    "        # X detect\n",
    "        elif pose_lmList[11][1] > pose_lmList[12][1] and pose_lmList[16][1] > pose_lmList[15][1] and cross_length_1 + cross_length_2 > wrist_length*2:\n",
    "            x_count += 1\n",
    "            o_present_count = 0\n",
    "            like_present_count = 0\n",
    "        \n",
    "        # LIKE detect\n",
    "        elif left_hand_fingersUp_list_a0[1:] == [0,0,0,0] and left_hand_fingersUp_list_a0[1:] == [0,0,0,0] and left_hand_fingersUp_list_a1 == [1,0,0,0,0] and left_hand_fingersUp_list_a1 == [1,0,0,0,0] and right_hand_lmList[4][2] < right_hand_lmList[2][2] and left_hand_lmList[4][2] < left_hand_lmList[2][2]:\n",
    "            like_count += 1\n",
    "            o_present_count = 0\n",
    "            x_present_count = 0\n",
    "    \n",
    "    else:\n",
    "        if len(pose_lmList) != 0:\n",
    "            wrist_length = detector.findLength_pose(16,15)\n",
    "            shoulder_length = detector.findLength_pose(12,11)\n",
    "            cross_length_1 = detector.findLength_pose(15,14)\n",
    "            cross_length_2 = detector.findLength_pose(16,13)\n",
    "\n",
    "            # O detect\n",
    "            if pose_lmList[16][1] < pose_lmList[15][1] and wrist_length < shoulder_length and pose_lmList[16][2] < pose_lmList[10][2] and pose_lmList[15][2] < pose_lmList[9][2] and elbow_length > shoulder_length:\n",
    "                o_count += 1\n",
    "                x_present_count = 0\n",
    "                like_present_count = 0\n",
    "\n",
    "            # X detect\n",
    "            elif pose_lmList[11][1] > pose_lmList[12][1] and pose_lmList[16][1] > pose_lmList[15][1] and cross_length_1 + cross_length_2 > wrist_length*2:\n",
    "                x_count += 1\n",
    "                o_present_count = 0\n",
    "                like_present_count = 0\n",
    "\n",
    "    # count control\n",
    "    if o_count > 10:\n",
    "        o_present_count = 15\n",
    "        o_count = 0\n",
    "        x_count = 0\n",
    "        like_count = 0\n",
    "    \n",
    "    if x_count > 10:\n",
    "        x_present_count = 15\n",
    "        o_count = 0\n",
    "        x_count = 0\n",
    "        like_count = 0\n",
    "\n",
    "    if like_count > 10:\n",
    "        like_present_count = 15\n",
    "        o_count = 0\n",
    "        x_count = 0\n",
    "        like_count = 0\n",
    "\n",
    "\n",
    "    if o_present_count > 0:\n",
    "        h, w, c = overlayList[0].shape\n",
    "        img[15:h+15, 15:w+15] = overlayList[0]\n",
    "        cv2.rectangle(img, (0, 0), (int(cap.get(3)), int(cap.get(4))), (225, 125, 75), 30)\n",
    "        o_present_count -= 1\n",
    "\n",
    "    if x_present_count > 0:\n",
    "        h, w, c = overlayList[1].shape\n",
    "        img[15:h+15, 15:w+15] = overlayList[1]\n",
    "        cv2.rectangle(img, (0, 0), (int(cap.get(3)), int(cap.get(4))), (55, 55, 240), 30)\n",
    "        x_present_count -= 1\n",
    "\n",
    "    if like_present_count > 0:\n",
    "        h, w, c = overlayList[2].shape\n",
    "        img[15:h+15, 15:w+15] = overlayList[2]\n",
    "        cv2.rectangle(img, (0, 0), (int(cap.get(3)), int(cap.get(4))), (40, 220, 30), 30)\n",
    "        like_present_count -= 1\n",
    "        \n",
    "        # turtlenect_detection(detector, img, sensitivity = 8, log=False, notification=True)\n",
    "\n",
    "        # eyeblink_detection(detector, img, sensitivity = 10, log=True, notification=True)\n",
    "\n",
    "    # fps_present(img, draw=True)                                                                                                                                                                          \n",
    "\n",
    "\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    # img를 우리에게 보여주는 부분\n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "    # ESC 키를 눌렀을 때 창을 모두 종료하는 부분\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b1783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first_ai",
   "language": "python",
   "name": "first_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
